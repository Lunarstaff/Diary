- 最开始的想法

目标网址：`http://www.nenmp.com/30`页面第一个图集的所有图片：  
第一个图集：`/html/body/div[1]/div[1]/a[1]`  
第二个图集：`/html/body/div[1]/div[1]/a[2]`  
.  
.  
.  
第十个图集：`/html/body/div[1]/div[1]/a[10]`  

建立图集对象`Album`有名称（ab_name），链接（ab_link），保存路径（ab_path），
图集中图片文件名前缀（image_name_pre）



---

#### 一、图片下载方案：
尝试下载下面链接的图片：
`target_image:http://bizhi.zhuoku.com/wall/jie/20070409/huoying/014.jpg`
http://nen.mnihao.com/up/nenmb/img/180228/1802280845395a95fbb32d382/5a95fbb6a8a4a.jpg
> 因为如果使用request.get之类的方法，就不像selenium使用webdriver一样模拟浏览器操作，
所以如果要打开某个链接最好加上浏览器header，这样可以防止目标网站把我们的请求给屏蔽了。 
- 找到我们之前在`Python`中使用的浏览器`header`：
    ```
    headers = {
    "Accept": "text/html,application/xhtml+xml,application/xml;"
          "q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
    "Cache-Control": "max-age=0",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
              "AppleWebKit/537.36 (KHTML, like Gecko) "
              "Chrome/77.0.3865.90 "
              "Safari/537.36",
    }
    ```
- 下面是我访问某图片网站时浏览器的`header`：
    ```
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
    Accept-Encoding: gzip, deflate
    Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
    Connection: keep-alive
    Cookie: UM_distinctid=16d8cf4a28a1e9-0146ea213da09b-67e1b3f-1fa400-16d8cf4a28b73d; CNZZDATA1271287794=1491433848-1570027769-%7C1571413173; Hm_lvt_0a1ff31ae133400f7d3eb6ef294dfe46=1570804479,1570940604,1571371144,1571416974; Hm_lpvt_0a1ff31ae133400f7d3eb6ef294dfe46=1571416980
    Host: www.nenmp.com
    Referer: http://www.nenmp.com/
    Upgrade-Insecure-Requests: 1
    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36
    ```
- 浏览器`header`解析：
    - `Accept`:
        >- 作用：浏览器端可以接受的媒体类型。
        >- 例如：`Accept: text/html` 代表浏览器可以接受服务器回发的类型为 `text/html` 也就是我们常说的html文档,
如果服务器无法返回text/html类型的数据,服务器应该返回一个406错误 `non acceptable` ，通配符 `*` 代表任意类型。
例如 `Accept: */*` 代表浏览器可以处理所有类型，（一般浏览器发给服务器都是发这个）

    - `Accept-Encoding`：
        >- 作用：定义客户端可以理解的编码机制，浏览器申明自己接收的编码方法，通常用来指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate），
        >- 例如：`Accept-Encoding: gzip,compress`
    - `Accept-Language`：
        >- 作用：浏览器申明自己接收的语言列表
        >- 语言跟字符集的区别：中文是语言，中文有多种字符集，比如`big5`、`gb2312`、`gbk`等
        >- 例如：`Accept-Language: zh-CN,zh;q=0.9,en;q=0.8`
    - `Connection`：
        >- 作用：表示是否需要持久连接，用于表明当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会不会关闭的通用头标。HTTP 1.1默认进行持久连接。
        >- 例如：`Connection: keep-alive` 当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接保持连接，客户端再次访问这个服务器上的网页，
        会继续使用这一条已经建立的连接
        >- `Connection: close`一个Request完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会关闭，当客户端再次发送Request，需要重新建立TCP连接.
    - `Host`：
        >- 作用: 请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的
        >- 例如: 我们在浏览器中输入：`http://www.hzau.edu.cn`浏览器发送的请求消息中，就会包含Host请求报头域，
        如下：`Host：www.hzau.edu.cn`此处使用缺省端口号80，若指定了端口号，则变成：Host：指定端口号
    - `Accept-Charset`:
        >- 浏览器可以接受的字符编码集
        >- 例如：`Accept-Charset: gb2312,utf-8;q=0.7,*;q=0.7`
    - ...后面用到的话再来补充吧！~


- 方案一，使用Python标准库中的`urllib`模块：  
    - 通过urllib.request.Request(url, headers=header)建立请求对象
    - 通过urllib.request.urlopen(请求对象)获得响应，写到本地保存为图片文件就OK了
    - 请示要加上header不然，你懂的！~
    - 方法成功了[`image_download.py`](./image_download.py)，但是有一个问题
        > 在用`urllib.request.urlopen`请求桌酷网的图片时只能请求成功一次，后面再发请求，
        网站给我返回的都是下面这个广告图片，不知道为什么？
        ![](./2019102022425.jpg)
        
        > 我把原图片链接放在这里，应该是[小樱](http://bizhi.zhuoku.com/wall/jie/20070409/huoying/014.jpg)。
         
- 方案二，使用requests库
